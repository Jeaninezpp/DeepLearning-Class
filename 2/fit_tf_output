/home/zpp/anaconda3/envs/tensorflow/bin/python /home/zpp/PycharmProjects/deeplearning/W2/fit_tf.py
2019-05-05 11:13:16.041818: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2019-05-05 11:13:16.041838: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2019-05-05 11:13:16.041842: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2019-05-05 11:13:16.041846: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2019-05-05 11:13:16.041849: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX512F instructions, but these are available on your machine and could speed up CPU computations.
2019-05-05 11:13:16.041852: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
---- 0 epoch ----
y_lab: [[-2.70957732]
 [-2.70902705]
 [-2.70847726]
 ...,
 [-1.7224772 ]
 [-1.72203326]
 [-1.72158957]]
loss : 5.42517


---- 1000 epoch ----
y_lab: [[ 0.1116941 ]
 [ 0.11150289]
 [ 0.1113112 ]
 ...,
 [-0.04090166]
 [-0.04087114]
 [-0.04084086]]
loss : 0.479931


---- 2000 epoch ----
y_lab: [[ 0.15975857]
 [ 0.15941286]
 [ 0.15906811]
 ...,
 [ 0.00830936]
 [ 0.00847721]
 [ 0.00864553]]
loss : 0.451348


---- 3000 epoch ----
y_lab: [[ 0.24204731]
 [ 0.24143505]
 [ 0.24082851]
 ...,
 [ 0.09256077]
 [ 0.09296608]
 [ 0.09337139]]
loss : 0.404631


---- 4000 epoch ----
y_lab: [[ 0.34379387]
 [ 0.34285545]
 [ 0.34192276]
 ...,
 [ 0.19672203]
 [ 0.19741821]
 [ 0.1981163 ]]
loss : 0.35077


---- 5000 epoch ----
y_lab: [[ 0.43797112]
 [ 0.43673134]
 [ 0.43549919]
 ...,
 [ 0.29313087]
 [ 0.2940979 ]
 [ 0.29506874]]
loss : 0.304741


---- 6000 epoch ----
y_lab: [[ 0.51969719]
 [ 0.51817513]
 [ 0.51666451]
 ...,
 [ 0.37885666]
 [ 0.38007927]
 [ 0.38129425]]
loss : 0.265425


---- 7000 epoch ----
y_lab: [[ 0.60935402]
 [ 0.60757256]
 [ 0.60580254]
 ...,
 [ 0.46720123]
 [ 0.46864891]
 [ 0.47009468]]
loss : 0.231849


---- 8000 epoch ----
y_lab: [[ 0.67456055]
 [ 0.67253876]
 [ 0.67052841]
 ...,
 [ 0.53742981]
 [ 0.5390892 ]
 [ 0.54076385]]
loss : 0.203254


---- 9000 epoch ----
y_lab: [[ 0.75799561]
 [ 0.75576019]
 [ 0.75353241]
 ...,
 [ 0.61720657]
 [ 0.61907196]
 [ 0.62092972]]
loss : 0.178956


---- 10000 epoch ----
y_lab: [[ 0.81118774]
 [ 0.80874634]
 [ 0.80632019]
 ...,
 [ 0.67531586]
 [ 0.67736053]
 [ 0.67939758]]
loss : 0.158306


---- 11000 epoch ----
y_lab: [[ 0.8692131 ]
 [ 0.86658096]
 [ 0.86397934]
 ...,
 [ 0.73474503]
 [ 0.73695374]
 [ 0.73916245]]
loss : 0.140716


---- 12000 epoch ----
y_lab: [[ 0.92314911]
 [ 0.92034912]
 [ 0.91756439]
 ...,
 [ 0.79003525]
 [ 0.79239655]
 [ 0.79476166]]
loss : 0.125586


---- 13000 epoch ----
y_lab: [[ 0.97319031]
 [ 0.9702301 ]
 [ 0.96727753]
 ...,
 [ 0.841259  ]
 [ 0.84377289]
 [ 0.84627533]]
loss : 0.112683


---- 14000 epoch ----
y_lab: [[ 1.01887512]
 [ 1.01576233]
 [ 1.01265717]
 ...,
 [ 0.88814926]
 [ 0.89078522]
 [ 0.8934288 ]]
loss : 0.101725


---- 15000 epoch ----
y_lab: [[ 1.06177521]
 [ 1.05853271]
 [ 1.05529785]
 ...,
 [ 0.93192291]
 [ 0.93467712]
 [ 0.93744659]]
loss : 0.0923831


---- 16000 epoch ----
y_lab: [[ 1.25369644]
 [ 1.25029373]
 [ 1.24690628]
 ...,
 [ 1.07051849]
 [ 1.07337189]
 [ 1.07622147]]
loss : 0.0999793


---- 17000 epoch ----
y_lab: [[ 1.13701248]
 [ 1.13352585]
 [ 1.13005447]
 ...,
 [ 1.00904083]
 [ 1.01200867]
 [ 1.01499176]]
loss : 0.0776329


---- 18000 epoch ----
y_lab: [[ 1.17823792]
 [ 1.17464447]
 [ 1.1710434 ]
 ...,
 [ 1.04834366]
 [ 1.05141068]
 [ 1.05449295]]
loss : 0.0718644


---- 19000 epoch ----
y_lab: [[ 1.20218658]
 [ 1.19848633]
 [ 1.19481659]
 ...,
 [ 1.07552338]
 [ 1.07868195]
 [ 1.08185577]]
loss : 0.0668904


---- 20000 epoch ----
y_lab: [[ 1.19284821]
 [ 1.18907166]
 [ 1.1852951 ]
 ...,
 [ 1.0802536 ]
 [ 1.08350372]
 [ 1.08674622]]
loss : 0.0636495


---- 21000 epoch ----
y_lab: [[ 1.2562027 ]
 [ 1.25234222]
 [ 1.24848175]
 ...,
 [ 1.131073  ]
 [ 1.13439178]
 [ 1.1377182 ]]
loss : 0.0591394


---- 22000 epoch ----
y_lab: [[ 1.28025818]
 [ 1.27631378]
 [ 1.27238464]
 ...,
 [ 1.15577698]
 [ 1.1591568 ]
 [ 1.16255951]]
loss : 0.0560998


---- 23000 epoch ----
y_lab: [[ 1.16912079]
 [ 1.16513824]
 [ 1.1611557 ]
 ...,
 [ 1.09272766]
 [ 1.09620667]
 [ 1.09967804]]
loss : 0.0655329


---- 24000 epoch ----
y_lab: [[ 1.32253265]
 [ 1.31845856]
 [ 1.31438446]
 ...,
 [ 1.19942474]
 [ 1.20293427]
 [ 1.20645142]]
loss : 0.0512785


---- 25000 epoch ----
y_lab: [[ 1.34236908]
 [ 1.33821869]
 [ 1.33408356]
 ...,
 [ 1.21944427]
 [ 1.2230072 ]
 [ 1.22657776]]
loss : 0.0493973


---- 26000 epoch ----
y_lab: [[ 1.36662292]
 [ 1.36242676]
 [ 1.35823059]
 ...,
 [ 1.241745  ]
 [ 1.24536133]
 [ 1.24898529]]
loss : 0.0478232


---- 27000 epoch ----
y_lab: [[ 1.40483093]
 [ 1.40055847]
 [ 1.39631653]
 ...,
 [ 1.27250671]
 [ 1.27617645]
 [ 1.27983856]]
loss : 0.0469626


---- 28000 epoch ----
y_lab: [[ 1.39096832]
 [ 1.38666534]
 [ 1.38239288]
 ...,
 [ 1.26927185]
 [ 1.27297211]
 [ 1.27669525]]
loss : 0.045275


---- 29000 epoch ----
y_lab: [[ 1.40378571]
 [ 1.39945221]
 [ 1.39511871]
 ...,
 [ 1.2828064 ]
 [ 1.28656006]
 [ 1.29030609]]
loss : 0.044282


w1: [[ 32.7768364]] w2: [[-47.53065491]] w3: [[-23.02753639]] bias: [ 79.36854553]
Converted 4 variables to const ops.

Process finished with exit code 0
